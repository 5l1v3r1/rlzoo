{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A modular version with LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "written November 2016 by Sam Greydanus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import gym\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Actor():\n",
    "    def __init__(self, batch_size, tsteps, xlen, ylen):\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        self.batch_size = batch_size\n",
    "        self.xlen = xlen\n",
    "        self.ylen = ylen\n",
    "        self.x = x = tf.placeholder(tf.float32, shape=[None, None, xlen], name=\"x\")\n",
    "        self.y = y = tf.placeholder(tf.float32, shape=[None, None, ylen], name=\"y\")\n",
    "        \n",
    "        self.params = params = {}\n",
    "        self.fc1_size = fc1_size = 50\n",
    "        self.rnn_size = rnn_size = 100\n",
    "        with tf.variable_scope('actor',reuse=False):\n",
    "            xavier_l1 = tf.truncated_normal_initializer(mean=0, stddev=1./np.sqrt(ylen), dtype=tf.float32)\n",
    "            params['W1'] = tf.get_variable(\"W1\", [xlen, fc1_size], initializer=xavier_l1)\n",
    "\n",
    "            rnn_init = tf.truncated_normal_initializer(stddev=0.075, dtype=tf.float32)\n",
    "            params['rnn'] = tf.nn.rnn_cell.LSTMCell(rnn_size, state_is_tuple=True, initializer=rnn_init)\n",
    "\n",
    "            params['istate_batch'] = params['rnn'].zero_state(batch_size=batch_size, dtype=tf.float32)\n",
    "            params['istate'] = params['rnn'].zero_state(batch_size=1, dtype=tf.float32)\n",
    "\n",
    "            xavier_l3 = tf.truncated_normal_initializer(stddev=1./np.sqrt(rnn_size), dtype=tf.float32)\n",
    "            params['W3'] = tf.get_variable(\"W3\", [rnn_size, ylen], initializer=xavier_l3)\n",
    "        \n",
    "        self.reset_state()\n",
    "            \n",
    "    def forward(self, x, state, tsteps, reuse=False):\n",
    "        with tf.variable_scope('actor', reuse=reuse):\n",
    "            x = tf.reshape(x, [-1, self.xlen])\n",
    "            h = tf.matmul(x, self.params['W1'])\n",
    "            h = tf.nn.relu(h) # ReLU nonlinearity\n",
    "#             h = tf.nn.dropout(h,0.8)\n",
    "\n",
    "            hs = [tf.squeeze(h_, [1]) for h_ in tf.split(1, tsteps, tf.reshape(h, [-1, tsteps, self.fc1_size]))]\n",
    "            rnn_outs, state = tf.nn.seq2seq.rnn_decoder(hs, state, self.params['rnn'], scope='actor')\n",
    "            rnn_out = tf.reshape(tf.concat(1, rnn_outs), [-1, self.rnn_size])\n",
    "            rnn_out = tf.nn.relu(rnn_out) # ReLU nonlinearity\n",
    "\n",
    "            logps = tf.matmul(rnn_out, self.params['W3'])\n",
    "            p = tf.nn.softmax(logps)\n",
    "            p = tf.reshape(p, [-1, self.ylen])\n",
    "        return p, state\n",
    "    \n",
    "    def reset_state(self):\n",
    "        self.c, self.h = self.params['istate'].c.eval(), self.params['istate'].h.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, n_obs, n_actions, gamma=0.99, lr = 1e-4, epsilon = 0.1):\n",
    "        self.gamma = gamma            # discount factor for reward\n",
    "        self.epsilon = epsilon\n",
    "        self.global_step = 0\n",
    "        self.xs, self.rs, self.ys = [],[],[]\n",
    "        \n",
    "        self.lr = lr               # learning rate for policy\n",
    "        self.n_obs = n_obs                     # dimensionality of observations\n",
    "        self.n_actions = n_actions             # number of available actions\n",
    "        \n",
    "        # make actor part of brain\n",
    "        self.batch_size = 8\n",
    "        self.tsteps = 20\n",
    "        self.actor = Actor(self.batch_size, self.tsteps, self.n_obs, self.n_actions)\n",
    "        \n",
    "        #placeholders\n",
    "        self.x = tf.placeholder(dtype=tf.float32, shape=[None, n_obs],name=\"x\")\n",
    "        self.y = tf.placeholder(dtype=tf.float32, shape=[None, n_actions],name=\"y\")\n",
    "        self.r = tf.placeholder(dtype=tf.float32, shape=[None, 1], name=\"r\")\n",
    "        \n",
    "        #gradient processing (PG magic)\n",
    "        self.discounted_r = self.discount_rewards(self.r, self.gamma)\n",
    "        mean, variance= tf.nn.moments(self.discounted_r, [0], shift=None, name=\"reward_moments\")\n",
    "        self.discounted_r -= mean\n",
    "        self.discounted_r /= tf.sqrt(variance + 1e-6)\n",
    "        \n",
    "        # initialize tf graph\n",
    "        self.y_hat, self.actor.params['fstate'] = \\\n",
    "                self.actor.forward(self.x, self.actor.params['istate'], 1, reuse=False)\n",
    "        self.y_hat_batch, _ = self.actor.forward(self.x, self.actor.params['istate_batch'], self.tsteps, reuse=True)\n",
    "        \n",
    "        self.loss = tf.nn.l2_loss(self.y-self.y_hat_batch)\n",
    "        self.optimizer = tf.train.RMSPropOptimizer(self.lr, decay=0.99)\n",
    "        self.grads = self.optimizer.compute_gradients(self.loss, \\\n",
    "                                    var_list=tf.trainable_variables(), grad_loss=self.discounted_r)\n",
    "        self.train_op = self.optimizer.apply_gradients(self.grads)\n",
    "\n",
    "        self.sess = tf.InteractiveSession()\n",
    "        tf.initialize_all_variables().run()\n",
    "        self.saver = tf.train.Saver(tf.all_variables())\n",
    "        self.actor.reset_state()\n",
    "    \n",
    "    def act(self, x):\n",
    "        feed = {self.x: x, self.actor.params['istate'].c: self.actor.c, self.actor.params['istate'].h: self.actor.h}\n",
    "        fetch = [self.y_hat, self.actor.params['fstate'].c, self.actor.params['fstate'].h]\n",
    "        [y_hat, self.actor.c, self.actor.h] = self.sess.run(fetch, feed)\n",
    "        y_hat = y_hat[0,:]\n",
    "        if np.random.rand() > 0.99985: print \"\\ty_hat is: \", y_hat\n",
    "        action = np.random.choice(self.n_actions,p=y_hat) if np.random.rand() > self.epsilon else np.random.randint(self.n_actions)\n",
    "        \n",
    "        label = np.zeros_like(y_hat) ; label[action] = 1\n",
    "        self.xs.append(x)\n",
    "        self.ys.append(label)\n",
    "        return action\n",
    "    \n",
    "    def learn(self):\n",
    "        epx = np.vstack(self.xs)\n",
    "        epr = np.vstack(self.rs)\n",
    "        epy = np.vstack(self.ys)\n",
    "        self.xs, self.rs, self.ys = [],[],[] # reset game history\n",
    "        \n",
    "        unit_len = self.batch_size*self.tsteps\n",
    "        buffer_len = ((unit_len - epx.shape[0]%unit_len)%unit_len)\n",
    "        epx_buffer = np.zeros((buffer_len,epx.shape[1]))\n",
    "        epr_buffer = np.zeros((buffer_len,epr.shape[1]))\n",
    "        epy_buffer = np.zeros((buffer_len,epy.shape[1]))\n",
    "        \n",
    "        epx = np.concatenate((epx, epx_buffer),axis=0)\n",
    "        epr = np.concatenate((epr, epr_buffer),axis=0)\n",
    "        epy = np.concatenate((epy, epy_buffer),axis=0)\n",
    "        \n",
    "        num_batches = epx.shape[0]/unit_len\n",
    "        for b in range(num_batches):\n",
    "            start = b*unit_len ; stop = (b+1)*unit_len\n",
    "            feed = {self.x: epx[start:stop,:], self.r: epr[start:stop,:], self.y: epy[start:stop,:]}\n",
    "            train_loss, _ = self.sess.run([self.loss, self.train_op],feed) # parameter update\n",
    "        self.global_step += 1\n",
    "        return train_loss\n",
    "        \n",
    "    @staticmethod\n",
    "    def discount_rewards(r, gamma):\n",
    "        discount_f = lambda a, v: (a*gamma + v)*(1-tf.abs(v)) + (v)*tf.abs(v);\n",
    "        r_reverse = tf.scan(discount_f, tf.reverse(r,[True, False]))\n",
    "        discounted_r = tf.reverse(r_reverse,[True, False])\n",
    "        return discounted_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepro(I):\n",
    "    \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n",
    "    I = I[35:195] # crop\n",
    "    I = I[::2,::2,0] # downsample by factor of 2\n",
    "    I[I == 144] = 0 # erase background (background type 1)\n",
    "    I[I == 109] = 0 # erase background (background type 2)\n",
    "    I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n",
    "    return I.astype(np.float).ravel()\n",
    "\n",
    "def plt_dynamic(x, y, ax, colors=['b']):\n",
    "    for color in colors:\n",
    "        ax.plot(x, y, color)\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-11-02 11:35:28,673] Making new env: Pong-v0\n"
     ]
    }
   ],
   "source": [
    "n_obs = 80*80   # dimensionality of observations\n",
    "n_actions = 3\n",
    "agent = Agent(n_obs, n_actions, gamma=0.992, lr = 1e-4, epsilon = 0.0)\n",
    "\n",
    "env = gym.make(\"Pong-v0\")\n",
    "observation = env.reset()\n",
    "prev_x = None\n",
    "running_reward = -20.48 # usually starts around 10 for cartpole\n",
    "reward_sum = 0\n",
    "episode_number = 0\n",
    "\n",
    "save_path = 'rnn_models/model.ckpt'\n",
    "saver = tf.train.Saver(tf.all_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no saved model to load. starting new session\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.all_variables())\n",
    "load_was_success = True # yes, I'm being optimistic\n",
    "try:\n",
    "    save_dir = '/'.join(save_path.split('/')[:-1])\n",
    "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
    "    load_path = ckpt.model_checkpoint_path\n",
    "    saver.restore(agent.sess, load_path)\n",
    "except:\n",
    "    print \"no saved model to load. starting new session\"\n",
    "    load_was_success = False\n",
    "else:\n",
    "    print \"loaded model: {}\".format(load_path)\n",
    "    saver = tf.train.Saver(tf.all_variables())\n",
    "    agent.global_step = int(load_path.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model overview:\n",
      "\tvariable \"actor/W1:0\" has 320000 parameters\n",
      "\tvariable \"actor/W3:0\" has 300 parameters\n",
      "\tvariable \"actor/actor/LSTMCell/W_0:0\" has 60000 parameters\n",
      "\tvariable \"actor/actor/LSTMCell/B:0\" has 400 parameters\n",
      "Total of 380700 parameters\n"
     ]
    }
   ],
   "source": [
    "total_parameters = 0 ; print \"Model overview:\"\n",
    "for variable in tf.trainable_variables():\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    print '\\tvariable \"{}\" has {} parameters' \\\n",
    "        .format(variable.name, variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print \"Total of {} parameters\".format(total_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode 0: starting up...\n",
      "ep: 0, reward: -21.0, mean reward: -20.485200\n",
      "\tep: 1, reward: -21.0\n",
      "\ty_hat is:  [ 0.31844577  0.39417684  0.28737745]\n",
      "\tep: 2, reward: -20.0\n",
      "\tep: 3, reward: -21.0\n",
      "\tep: 4, reward: -18.0\n",
      "\tep: 5, reward: -20.0\n",
      "\ty_hat is:  [ 0.28998578  0.36792362  0.34209058]\n",
      "\tep: 6, reward: -20.0\n",
      "\tep: 7, reward: -21.0\n",
      "\tep: 8, reward: -20.0\n",
      "\tep: 9, reward: -19.0\n",
      "ep: 10, reward: -20.0, mean reward: -20.438235\n",
      "\tep: 11, reward: -21.0\n",
      "\tep: 12, reward: -21.0\n",
      "\ty_hat is:  [ 0.27122653  0.42047504  0.30829847]\n",
      "\tep: 13, reward: -21.0\n",
      "\tep: 14, reward: -20.0\n",
      "\tep: 15, reward: -21.0\n",
      "\tep: 16, reward: -21.0\n",
      "\tep: 17, reward: -19.0\n",
      "\ty_hat is:  [ 0.31272689  0.37749279  0.30978033]\n",
      "\tep: 18, reward: -21.0\n",
      "\ty_hat is:  [ 0.31730932  0.36701009  0.31568059]\n",
      "\tep: 19, reward: -20.0\n",
      "ep: 20, reward: -21.0, mean reward: -20.453229\n",
      "\tep: 21, reward: -21.0\n",
      "\tep: 22, reward: -21.0\n",
      "\ty_hat is:  [ 0.29132509  0.39021432  0.31846058]\n",
      "\tep: 23, reward: -21.0\n",
      "\tep: 24, reward: -21.0\n",
      "\tep: 25, reward: -20.0\n",
      "\tep: 26, reward: -21.0\n",
      "\tep: 27, reward: -21.0\n",
      "\tep: 28, reward: -21.0\n",
      "\tep: 29, reward: -21.0\n",
      "ep: 30, reward: -21.0, mean reward: -20.496001\n",
      "\tep: 31, reward: -21.0\n",
      "\tep: 32, reward: -20.0\n",
      "\tep: 33, reward: -21.0\n",
      "\tep: 34, reward: -19.0\n",
      "\tep: 35, reward: -21.0\n",
      "\tep: 36, reward: -21.0\n",
      "\tep: 37, reward: -21.0\n",
      "\tep: 38, reward: -21.0\n",
      "\ty_hat is:  [ 0.29909003  0.39223859  0.30867141]\n",
      "\tep: 39, reward: -21.0\n",
      "ep: 40, reward: -21.0, mean reward: -20.516135\n",
      "\tep: 41, reward: -21.0\n",
      "\tep: 42, reward: -21.0\n",
      "\tep: 43, reward: -19.0\n",
      "\tep: 44, reward: -21.0\n",
      "\tep: 45, reward: -21.0\n",
      "\tep: 46, reward: -21.0\n",
      "\tep: 47, reward: -21.0\n",
      "\tep: 48, reward: -21.0\n",
      "\tep: 49, reward: -21.0\n",
      "ep: 50, reward: -19.0, mean reward: -20.523760\n",
      "\tep: 51, reward: -21.0\n",
      "\ty_hat is:  [ 0.30050948  0.40352502  0.29596546]\n",
      "\tep: 52, reward: -21.0\n",
      "\tep: 53, reward: -21.0\n",
      "\tep: 54, reward: -20.0\n",
      "\tep: 55, reward: -21.0\n",
      "\tep: 56, reward: -21.0\n",
      "\tep: 57, reward: -21.0\n",
      "\tep: 58, reward: -21.0\n",
      "\ty_hat is:  [ 0.31686816  0.39790577  0.28522605]\n",
      "\tep: 59, reward: -21.0\n",
      "ep: 60, reward: -21.0, mean reward: -20.559882\n",
      "\ty_hat is:  [ 0.29537722  0.4446221   0.26000062]\n",
      "\tep: 61, reward: -19.0\n",
      "\ty_hat is:  [ 0.30781907  0.34377414  0.3484067 ]\n",
      "\tep: 62, reward: -21.0\n",
      "\tep: 63, reward: -21.0\n",
      "\tep: 64, reward: -19.0\n",
      "\tep: 65, reward: -21.0\n",
      "\tep: 66, reward: -21.0\n",
      "\tep: 67, reward: -21.0\n",
      "\tep: 68, reward: -20.0\n",
      "\tep: 69, reward: -21.0\n",
      "ep: 70, reward: -21.0, mean reward: -20.555064\n",
      "\tep: 71, reward: -21.0\n",
      "\tep: 72, reward: -21.0\n",
      "\tep: 73, reward: -20.0\n",
      "\tep: 74, reward: -21.0\n",
      "\tep: 75, reward: -21.0\n",
      "\tep: 76, reward: -19.0\n",
      "\tep: 77, reward: -21.0\n",
      "\tep: 78, reward: -19.0\n",
      "\tep: 79, reward: -20.0\n",
      "ep: 80, reward: -21.0, mean reward: -20.539574\n",
      "\tep: 81, reward: -20.0\n",
      "\tep: 82, reward: -20.0\n",
      "\tep: 83, reward: -20.0\n",
      "\tep: 84, reward: -21.0\n",
      "\tep: 85, reward: -20.0\n",
      "\tep: 86, reward: -20.0\n",
      "\tep: 87, reward: -20.0\n",
      "\tep: 88, reward: -21.0\n",
      "\tep: 89, reward: -20.0\n",
      "ep: 90, reward: -20.0, mean reward: -20.507196\n",
      "\tep: 91, reward: -21.0\n",
      "\tep: 92, reward: -21.0\n",
      "\tep: 93, reward: -19.0\n",
      "\tep: 94, reward: -21.0\n",
      "\tep: 95, reward: -20.0\n",
      "\tep: 96, reward: -21.0\n",
      "\ty_hat is:  [ 0.35071099  0.27594048  0.37334853]\n",
      "\tep: 97, reward: -21.0\n",
      "\ty_hat is:  [ 0.33957618  0.30639282  0.35403097]\n",
      "\tep: 98, reward: -21.0\n",
      "\tep: 99, reward: -21.0\n",
      "ep: 100, reward: -20.0, mean reward: -20.516166\n",
      "\tep: 101, reward: -21.0\n",
      "\tep: 102, reward: -21.0\n",
      "\tep: 103, reward: -20.0\n",
      "\tep: 104, reward: -21.0\n",
      "\tep: 105, reward: -21.0\n",
      "\tep: 106, reward: -19.0\n",
      "\tep: 107, reward: -20.0\n",
      "\tep: 108, reward: -21.0\n",
      "\ty_hat is:  [ 0.38049462  0.29369539  0.32581002]\n",
      "\tep: 109, reward: -21.0\n",
      "ep: 110, reward: -21.0, mean reward: -20.524194\n",
      "\ty_hat is:  [ 0.30310208  0.34186915  0.35502875]\n",
      "\tep: 111, reward: -19.0\n",
      "\tep: 112, reward: -21.0\n",
      "\ty_hat is:  [ 0.33403346  0.30211854  0.36384797]\n",
      "\tep: 113, reward: -21.0\n",
      "\tep: 114, reward: -20.0\n",
      "\tep: 115, reward: -21.0\n",
      "\tep: 116, reward: -21.0\n",
      "\tep: 117, reward: -21.0\n",
      "\ty_hat is:  [ 0.31570601  0.31157646  0.37271756]\n",
      "\tep: 118, reward: -19.0\n",
      "\tep: 119, reward: -21.0\n",
      "ep: 120, reward: -21.0, mean reward: -20.522402\n",
      "\tep: 121, reward: -21.0\n",
      "\ty_hat is:  [ 0.33945316  0.32770079  0.33284605]\n",
      "\tep: 122, reward: -20.0\n",
      "\tep: 123, reward: -21.0\n",
      "\tep: 124, reward: -19.0\n",
      "\tep: 125, reward: -20.0\n",
      "\tep: 126, reward: -20.0\n",
      "\ty_hat is:  [ 0.35268378  0.30896428  0.33835191]\n",
      "\tep: 127, reward: -21.0\n",
      "\tep: 128, reward: -21.0\n",
      "\tep: 129, reward: -21.0\n",
      "\ty_hat is:  [ 0.34331179  0.29764855  0.35903963]\n",
      "ep: 130, reward: -20.0, mean reward: -20.510896\n",
      "\tep: 131, reward: -21.0\n",
      "\tep: 132, reward: -18.0\n",
      "\tep: 133, reward: -20.0\n",
      "\tep: 134, reward: -20.0\n",
      "\tep: 135, reward: -20.0\n",
      "\tep: 136, reward: -20.0\n",
      "\tep: 137, reward: -20.0\n",
      "\tep: 138, reward: -21.0\n",
      "\tep: 139, reward: -20.0\n",
      "ep: 140, reward: -20.0, mean reward: -20.462527\n",
      "\ty_hat is:  [ 0.33909759  0.28021455  0.38068786]\n",
      "\tep: 141, reward: -20.0\n",
      "\ty_hat is:  [ 0.36307529  0.26380929  0.37311539]\n",
      "\ty_hat is:  [ 0.33929285  0.30088636  0.35982069]\n",
      "\tep: 142, reward: -21.0\n",
      "\tep: 143, reward: -21.0\n",
      "\tep: 144, reward: -21.0\n",
      "\tep: 145, reward: -20.0\n",
      "\ty_hat is:  [ 0.3548978   0.27529079  0.36981145]\n",
      "\tep: 146, reward: -19.0\n",
      "\ty_hat is:  [ 0.33756232  0.3011882   0.36124945]\n",
      "\tep: 147, reward: -20.0\n",
      "\tep: 148, reward: -20.0\n",
      "\tep: 149, reward: -20.0\n",
      "ep: 150, reward: -21.0, mean reward: -20.446658\n",
      "\ty_hat is:  [ 0.33322874  0.26051587  0.40625536]\n",
      "\tep: 151, reward: -20.0\n",
      "\tep: 152, reward: -21.0\n",
      "\tep: 153, reward: -21.0\n",
      "\tep: 154, reward: -21.0\n",
      "\tep: 155, reward: -21.0\n",
      "\tep: 156, reward: -18.0\n",
      "\tep: 157, reward: -21.0\n",
      "\ty_hat is:  [ 0.34683874  0.2753987   0.37776253]\n",
      "\tep: 158, reward: -20.0\n",
      "\ty_hat is:  [ 0.36971349  0.2563614   0.37392506]\n",
      "\tep: 159, reward: -21.0\n",
      "ep: 160, reward: -21.0, mean reward: -20.451813\n",
      "\ty_hat is:  [ 0.33735114  0.27229694  0.39035183]\n",
      "\tep: 161, reward: -20.0\n",
      "\ty_hat is:  [ 0.35574058  0.26012051  0.38413891]\n",
      "\tep: 162, reward: -20.0\n",
      "\tep: 163, reward: -21.0\n",
      "\tep: 164, reward: -21.0\n",
      "\tep: 165, reward: -18.0\n",
      "\tep: 166, reward: -20.0\n",
      "\tep: 167, reward: -20.0\n",
      "\ty_hat is:  [ 0.34357476  0.28666297  0.36976227]\n",
      "\tep: 168, reward: -19.0\n",
      "\tep: 169, reward: -21.0\n",
      "\ty_hat is:  [ 0.30942911  0.31700951  0.37356135]\n",
      "ep: 170, reward: -19.0, mean reward: -20.398426\n",
      "\tep: 171, reward: -21.0\n",
      "\tep: 172, reward: -21.0\n",
      "\tep: 173, reward: -19.0\n",
      "\tep: 174, reward: -19.0\n",
      "\tep: 175, reward: -19.0\n",
      "\tep: 176, reward: -20.0\n",
      "\ty_hat is:  [ 0.3185856   0.29317725  0.38823718]\n",
      "\tep: 177, reward: -19.0\n",
      "\ty_hat is:  [ 0.33397856  0.26128775  0.40473363]\n",
      "\tep: 178, reward: -21.0\n",
      "\ty_hat is:  [ 0.28172359  0.32207873  0.39619768]\n",
      "\tep: 179, reward: -20.0\n",
      "ep: 180, reward: -20.0, mean reward: -20.350545\n",
      "\tep: 181, reward: -20.0\n",
      "\tep: 182, reward: -21.0\n",
      "\tep: 183, reward: -21.0\n",
      "\tep: 184, reward: -21.0\n",
      "\tep: 185, reward: -20.0\n",
      "\tep: 186, reward: -21.0\n",
      "\tep: 187, reward: -20.0\n",
      "\tep: 188, reward: -21.0\n",
      "\tep: 189, reward: -19.0\n",
      "\ty_hat is:  [ 0.31501424  0.31320697  0.37177885]\n",
      "ep: 190, reward: -21.0, mean reward: -20.364496\n",
      "\tep: 191, reward: -21.0\n",
      "\tep: 192, reward: -21.0\n",
      "\tep: 193, reward: -19.0\n",
      "\tep: 194, reward: -20.0\n",
      "\tep: 195, reward: -21.0\n",
      "\ty_hat is:  [ 0.31674406  0.27707642  0.40617949]\n",
      "\tep: 196, reward: -19.0\n",
      "\tep: 197, reward: -21.0\n",
      "\ty_hat is:  [ 0.3193121   0.26247665  0.41821122]\n",
      "\tep: 198, reward: -21.0\n",
      "\tep: 199, reward: -21.0\n",
      "ep: 200, reward: -18.0, mean reward: -20.347994\n",
      "\ty_hat is:  [ 0.30281305  0.30465838  0.39252862]\n",
      "\tep: 201, reward: -21.0\n",
      "\tep: 202, reward: -20.0\n",
      "\tep: 203, reward: -21.0\n",
      "\tep: 204, reward: -20.0\n",
      "\tep: 205, reward: -21.0\n",
      "\ty_hat is:  [ 0.3402791   0.23650923  0.42321166]\n",
      "\tep: 206, reward: -20.0\n",
      "\tep: 207, reward: -21.0\n",
      "\tep: 208, reward: -21.0\n",
      "\tep: 209, reward: -21.0\n",
      "ep: 210, reward: -21.0, mean reward: -20.382089\n",
      "\tep: 211, reward: -21.0\n",
      "\tep: 212, reward: -20.0\n",
      "\tep: 213, reward: -21.0\n",
      "\tep: 214, reward: -20.0\n",
      "\tep: 215, reward: -21.0\n",
      "\tep: 216, reward: -18.0\n",
      "\tep: 217, reward: -20.0\n",
      "\tep: 218, reward: -20.0\n",
      "\tep: 219, reward: -21.0\n",
      "ep: 220, reward: -21.0, mean reward: -20.374208\n",
      "\ty_hat is:  [ 0.29907778  0.31169367  0.38922852]\n",
      "\tep: 221, reward: -21.0\n",
      "\ty_hat is:  [ 0.35565692  0.29107437  0.35326871]\n",
      "\tep: 222, reward: -20.0\n",
      "\tep: 223, reward: -20.0\n",
      "\tep: 224, reward: -20.0\n",
      "\tep: 225, reward: -20.0\n",
      "\tep: 226, reward: -20.0\n",
      "\tep: 227, reward: -21.0\n",
      "\tep: 228, reward: -21.0\n",
      "\ty_hat is:  [ 0.3419255   0.27466697  0.38340753]\n",
      "\tep: 229, reward: -21.0\n",
      "ep: 230, reward: -21.0, mean reward: -20.386967\n",
      "\ty_hat is:  [ 0.39380449  0.23789786  0.3682977 ]\n",
      "\tep: 231, reward: -19.0\n",
      "\tep: 232, reward: -20.0\n",
      "\tep: 233, reward: -20.0\n",
      "\tep: 234, reward: -21.0\n",
      "\tep: 235, reward: -21.0\n",
      "\tep: 236, reward: -21.0\n",
      "\ty_hat is:  [ 0.33551651  0.31459263  0.34989089]\n",
      "\tep: 237, reward: -21.0\n",
      "\tep: 238, reward: -21.0\n",
      "\ty_hat is:  [ 0.32073343  0.33900326  0.34026325]\n",
      "\tep: 239, reward: -20.0\n",
      "ep: 240, reward: -21.0, mean reward: -20.398865\n",
      "\ty_hat is:  [ 0.32913312  0.36630082  0.30456606]\n",
      "\tep: 241, reward: -21.0\n",
      "\tep: 242, reward: -18.0\n",
      "\tep: 243, reward: -20.0\n",
      "\tep: 244, reward: -19.0\n",
      "\tep: 245, reward: -20.0\n",
      "\tep: 246, reward: -21.0\n",
      "\tep: 247, reward: -21.0\n",
      "\tep: 248, reward: -21.0\n",
      "\tep: 249, reward: -21.0\n",
      "ep: 250, reward: -20.0, mean reward: -20.381002\n",
      "\tep: 251, reward: -21.0\n",
      "\tep: 252, reward: -21.0\n",
      "\tep: 253, reward: -21.0\n",
      "\ty_hat is:  [ 0.31108195  0.36981761  0.31910041]\n",
      "\tep: 254, reward: -21.0\n",
      "\tep: 255, reward: -21.0\n",
      "\tep: 256, reward: -21.0\n",
      "\tep: 257, reward: -21.0\n",
      "\tep: 258, reward: -21.0\n",
      "\tep: 259, reward: -21.0\n",
      "\ty_hat is:  [ 0.31493562  0.3866502   0.29841417]\n",
      "\ty_hat is:  [ 0.35105801  0.34165856  0.30728346]\n",
      "ep: 260, reward: -21.0, mean reward: -20.440189\n",
      "\tep: 261, reward: -21.0\n",
      "\tep: 262, reward: -21.0\n",
      "\ty_hat is:  [ 0.31283963  0.33842447  0.34873587]\n",
      "\ty_hat is:  [ 0.33225688  0.33411446  0.33362865]\n",
      "\tep: 263, reward: -21.0\n",
      "\tep: 264, reward: -21.0\n",
      "\tep: 265, reward: -21.0\n",
      "\tep: 266, reward: -20.0\n",
      "\tep: 267, reward: -21.0\n",
      "\ty_hat is:  [ 0.36623651  0.32180801  0.31195545]\n",
      "\tep: 268, reward: -20.0\n",
      "\tep: 269, reward: -20.0\n",
      "ep: 270, reward: -20.0, mean reward: -20.454410\n",
      "\tep: 271, reward: -21.0\n",
      "\tep: 272, reward: -21.0\n",
      "\tep: 273, reward: -20.0\n",
      "\tep: 274, reward: -19.0\n",
      "\ty_hat is:  [ 0.27789813  0.33949748  0.38260436]\n",
      "\tep: 275, reward: -20.0\n",
      "\tep: 276, reward: -18.0\n",
      "\ty_hat is:  [ 0.32610711  0.32214257  0.3517504 ]\n",
      "\tep: 277, reward: -21.0\n",
      "\tep: 278, reward: -21.0\n",
      "\ty_hat is:  [ 0.31924695  0.31332377  0.36742932]\n",
      "\tep: 279, reward: -20.0\n",
      "ep: 280, reward: -21.0, mean reward: -20.430200\n",
      "\ty_hat is:  [ 0.28593543  0.31756094  0.3965036 ]\n",
      "\tep: 281, reward: -21.0\n",
      "\tep: 282, reward: -21.0\n",
      "\tep: 283, reward: -21.0\n",
      "\ty_hat is:  [ 0.31832477  0.34070215  0.34097305]\n",
      "\tep: 284, reward: -21.0\n",
      "\tep: 285, reward: -21.0\n",
      "\tep: 286, reward: -20.0\n",
      "\tep: 287, reward: -20.0\n",
      "\tep: 288, reward: -21.0\n",
      "\tep: 289, reward: -21.0\n",
      "ep: 290, reward: -21.0, mean reward: -20.465374\n",
      "\tep: 291, reward: -21.0\n",
      "\tep: 292, reward: -21.0\n",
      "\tep: 293, reward: -19.0\n",
      "\tep: 294, reward: -20.0\n",
      "\ty_hat is:  [ 0.31076321  0.30751479  0.38172203]\n",
      "\ty_hat is:  [ 0.31529695  0.27392802  0.41077504]\n",
      "\ty_hat is:  [ 0.32013711  0.28901896  0.39084396]\n",
      "\tep: 295, reward: -21.0\n",
      "\tep: 296, reward: -20.0\n",
      "\tep: 297, reward: -21.0\n",
      "\tep: 298, reward: -20.0\n",
      "\tep: 299, reward: -20.0\n",
      "ep: 300, reward: -19.0, mean reward: -20.439131\n",
      "\tep: 301, reward: -21.0\n",
      "\tep: 302, reward: -20.0\n",
      "\ty_hat is:  [ 0.30241668  0.28256577  0.41501755]\n",
      "\tep: 303, reward: -21.0\n",
      "\ty_hat is:  [ 0.3281396   0.29586568  0.37599474]\n",
      "\tep: 304, reward: -21.0\n",
      "\tep: 305, reward: -20.0\n",
      "\ty_hat is:  [ 0.30724499  0.2901831   0.40257195]\n",
      "\tep: 306, reward: -21.0\n",
      "\tep: 307, reward: -20.0\n",
      "\tep: 308, reward: -21.0\n",
      "\ty_hat is:  [ 0.30862617  0.3090646   0.3823092 ]\n",
      "\tep: 309, reward: -21.0\n",
      "ep: 310, reward: -20.0, mean reward: -20.454320\n",
      "\tep: 311, reward: -21.0\n",
      "\tep: 312, reward: -21.0\n",
      "\tep: 313, reward: -21.0\n",
      "\tep: 314, reward: -20.0\n",
      "\ty_hat is:  [ 0.30085117  0.24127844  0.45787036]\n",
      "\tep: 315, reward: -21.0\n",
      "\tep: 316, reward: -21.0\n",
      "\ty_hat is:  [ 0.32745391  0.26681465  0.4057315 ]\n",
      "\tep: 317, reward: -20.0\n",
      "\tep: 318, reward: -21.0\n",
      "\tep: 319, reward: -19.0\n",
      "ep: 320, reward: -20.0, mean reward: -20.457579\n",
      "\tep: 321, reward: -21.0\n",
      "\tep: 322, reward: -21.0\n",
      "\tep: 323, reward: -21.0\n",
      "\ty_hat is:  [ 0.3464728   0.25928646  0.39424074]\n",
      "\tep: 324, reward: -20.0\n",
      "\tep: 325, reward: -20.0\n",
      "\tep: 326, reward: -21.0\n",
      "\tep: 327, reward: -21.0\n",
      "\tep: 328, reward: -20.0\n",
      "\tep: 329, reward: -21.0\n",
      "\ty_hat is:  [ 0.31054091  0.3233555   0.36610359]\n",
      "ep: 330, reward: -20.0, mean reward: -20.470718\n",
      "\tep: 331, reward: -21.0\n",
      "\tep: 332, reward: -21.0\n",
      "\tep: 333, reward: -18.0\n",
      "\tep: 334, reward: -21.0\n",
      "\tep: 335, reward: -21.0\n",
      "\ty_hat is:  [ 0.29917854  0.31418753  0.38663393]\n",
      "\tep: 336, reward: -20.0\n",
      "\tep: 337, reward: -21.0\n",
      "\tep: 338, reward: -20.0\n",
      "\tep: 339, reward: -20.0\n",
      "ep: 340, reward: -21.0, mean reward: -20.464058\n",
      "\tep: 341, reward: -20.0\n",
      "\ty_hat is:  [ 0.27588215  0.36509308  0.35902473]\n",
      "\tep: 342, reward: -21.0\n",
      "\tep: 343, reward: -18.0\n",
      "\ty_hat is:  [ 0.28305015  0.36097088  0.35597897]\n",
      "\tep: 344, reward: -21.0\n",
      "\tep: 345, reward: -21.0\n",
      "\tep: 346, reward: -21.0\n",
      "\ty_hat is:  [ 0.25357074  0.31169391  0.43473536]\n",
      "\tep: 347, reward: -20.0\n",
      "\tep: 348, reward: -20.0\n",
      "\ty_hat is:  [ 0.32033384  0.27978346  0.39988264]\n",
      "\tep: 349, reward: -21.0\n",
      "ep: 350, reward: -20.0, mean reward: -20.448703\n",
      "\tep: 351, reward: -21.0\n",
      "\tep: 352, reward: -20.0\n",
      "\tep: 353, reward: -19.0\n",
      "\tep: 354, reward: -21.0\n",
      "\tep: 355, reward: -21.0\n",
      "\tep: 356, reward: -21.0\n",
      "\tep: 357, reward: -21.0\n",
      "\tep: 358, reward: -18.0\n",
      "\tep: 359, reward: -20.0\n",
      "ep: 360, reward: -21.0, mean reward: -20.434245\n",
      "\ty_hat is:  [ 0.29546568  0.38720328  0.31733111]\n",
      "\tep: 361, reward: -19.0\n",
      "\tep: 362, reward: -20.0\n",
      "\ty_hat is:  [ 0.33871624  0.29013216  0.37115163]\n",
      "\tep: 363, reward: -20.0\n",
      "\tep: 364, reward: -21.0\n",
      "\tep: 365, reward: -20.0\n",
      "\tep: 366, reward: -21.0\n",
      "\tep: 367, reward: -21.0\n",
      "\tep: 368, reward: -21.0\n",
      "\tep: 369, reward: -21.0\n",
      "ep: 370, reward: -21.0, mean reward: -20.442013\n",
      "\tep: 371, reward: -20.0\n",
      "\tep: 372, reward: -21.0\n",
      "\tep: 373, reward: -20.0\n",
      "\tep: 374, reward: -21.0\n",
      "\tep: 375, reward: -20.0\n",
      "\tep: 376, reward: -21.0\n",
      "\tep: 377, reward: -20.0\n",
      "\tep: 378, reward: -20.0\n",
      "\tep: 379, reward: -21.0\n",
      "ep: 380, reward: -21.0, mean reward: -20.447897\n",
      "\tep: 381, reward: -20.0\n",
      "\tep: 382, reward: -21.0\n",
      "\ty_hat is:  [ 0.32876939  0.34149829  0.32973236]\n",
      "\tep: 383, reward: -21.0\n",
      "\tep: 384, reward: -20.0\n",
      "\tep: 385, reward: -20.0\n",
      "\ty_hat is:  [ 0.33459857  0.35561422  0.30978718]\n",
      "\tep: 386, reward: -21.0\n",
      "\tep: 387, reward: -20.0\n",
      "\tep: 388, reward: -20.0\n",
      "\tep: 389, reward: -21.0\n",
      "ep: 390, reward: -20.0, mean reward: -20.443124\n",
      "\tep: 391, reward: -21.0\n",
      "\tep: 392, reward: -21.0\n",
      "\tep: 393, reward: -21.0\n",
      "\tep: 394, reward: -21.0\n",
      "\tep: 395, reward: -21.0\n",
      "\ty_hat is:  [ 0.34834009  0.35132512  0.30033478]\n",
      "\tep: 396, reward: -21.0\n",
      "\ty_hat is:  [ 0.34728229  0.32260692  0.33011079]\n",
      "\tep: 397, reward: -20.0\n",
      "\tep: 398, reward: -19.0\n",
      "\tep: 399, reward: -21.0\n",
      "ep: 400, reward: -20.0, mean reward: -20.457066\n",
      "\tep: 401, reward: -21.0\n",
      "\tep: 402, reward: -20.0\n",
      "\tep: 403, reward: -20.0\n",
      "\tep: 404, reward: -21.0\n",
      "\tep: 405, reward: -20.0\n",
      "\tep: 406, reward: -21.0\n",
      "\tep: 407, reward: -19.0\n",
      "\tep: 408, reward: -18.0\n",
      "\tep: 409, reward: -21.0\n",
      "ep: 410, reward: -21.0, mean reward: -20.432113\n",
      "\ty_hat is:  [ 0.36607009  0.30679575  0.32713419]\n",
      "\tep: 411, reward: -21.0\n",
      "\tep: 412, reward: -21.0\n",
      "\tep: 413, reward: -20.0\n",
      "\tep: 414, reward: -21.0\n",
      "\ty_hat is:  [ 0.30831704  0.36028424  0.33139876]\n",
      "\tep: 415, reward: -21.0\n",
      "\tep: 416, reward: -21.0\n",
      "\tep: 417, reward: -19.0\n",
      "\ty_hat is:  [ 0.38986802  0.34163699  0.26849499]\n",
      "\tep: 418, reward: -20.0\n",
      "\tep: 419, reward: -21.0\n",
      "\ty_hat is:  [ 0.38294673  0.31052101  0.30653229]\n",
      "ep: 420, reward: -21.0, mean reward: -20.447886\n",
      "\tep: 421, reward: -20.0\n",
      "\tep: 422, reward: -20.0\n",
      "\ty_hat is:  [ 0.36308217  0.38372368  0.25319412]\n",
      "\tep: 423, reward: -21.0\n",
      "\tep: 424, reward: -21.0\n",
      "\ty_hat is:  [ 0.37924606  0.33445969  0.28629425]\n",
      "\ty_hat is:  [ 0.35777169  0.39673007  0.24549821]\n",
      "\tep: 425, reward: -21.0\n",
      "\ty_hat is:  [ 0.35958192  0.37184691  0.2685712 ]\n",
      "\ty_hat is:  [ 0.3946583   0.35265589  0.25268579]\n",
      "\tep: 426, reward: -21.0\n",
      "\ty_hat is:  [ 0.3872484   0.34048161  0.27227002]\n",
      "\tep: 427, reward: -21.0\n",
      "\ty_hat is:  [ 0.39801103  0.31642032  0.28556865]\n",
      "\ty_hat is:  [ 0.39746648  0.35059306  0.25194037]\n",
      "\tep: 428, reward: -19.0\n",
      "\tep: 429, reward: -21.0\n",
      "\ty_hat is:  [ 0.449247    0.30391824  0.24683474]\n",
      "ep: 430, reward: -21.0, mean reward: -20.462713\n",
      "\tep: 431, reward: -21.0\n",
      "\tep: 432, reward: -21.0\n",
      "\tep: 433, reward: -21.0\n",
      "\tep: 434, reward: -20.0\n",
      "\ty_hat is:  [ 0.42396784  0.28746575  0.28856644]\n",
      "\tep: 435, reward: -19.0\n",
      "\ty_hat is:  [ 0.40791836  0.34011948  0.25196213]\n",
      "\tep: 436, reward: -19.0\n",
      "\tep: 437, reward: -21.0\n",
      "\tep: 438, reward: -21.0\n",
      "\ty_hat is:  [ 0.42565748  0.261538    0.31280449]\n",
      "\tep: 439, reward: -21.0\n",
      "ep: 440, reward: -20.0, mean reward: -20.456441\n",
      "\tep: 441, reward: -21.0\n",
      "\ty_hat is:  [ 0.36984146  0.30614614  0.32401243]\n",
      "\tep: 442, reward: -21.0\n",
      "\tep: 443, reward: -21.0\n",
      "\tep: 444, reward: -20.0\n",
      "\tep: 445, reward: -21.0\n",
      "\ty_hat is:  [ 0.40051284  0.31463248  0.28485465]\n",
      "\tep: 446, reward: -20.0\n",
      "\tep: 447, reward: -20.0\n",
      "\tep: 448, reward: -21.0\n",
      "\tep: 449, reward: -21.0\n",
      "ep: 450, reward: -21.0, mean reward: -20.479691\n",
      "\tep: 451, reward: -21.0\n",
      "\tep: 452, reward: -21.0\n",
      "\tep: 453, reward: -20.0\n",
      "\tep: 454, reward: -21.0\n",
      "\tep: 455, reward: -21.0\n",
      "\tep: 456, reward: -21.0\n",
      "\tep: 457, reward: -18.0\n",
      "\tep: 458, reward: -21.0\n",
      "\tep: 459, reward: -20.0\n",
      "ep: 460, reward: -20.0, mean reward: -20.471112\n",
      "\ty_hat is:  [ 0.31475627  0.36161739  0.32362634]\n",
      "\tep: 461, reward: -19.0\n",
      "\ty_hat is:  [ 0.36968872  0.3163313   0.31398001]\n",
      "\tep: 462, reward: -20.0\n",
      "\tep: 463, reward: -20.0\n",
      "\tep: 464, reward: -21.0\n",
      "\tep: 465, reward: -21.0\n",
      "\tep: 466, reward: -20.0\n",
      "\tep: 467, reward: -20.0\n",
      "\tep: 468, reward: -21.0\n",
      "\tep: 469, reward: -21.0\n",
      "ep: 470, reward: -21.0, mean reward: -20.465556\n",
      "\tep: 471, reward: -21.0\n",
      "\tep: 472, reward: -21.0\n",
      "\tep: 473, reward: -21.0\n",
      "\ty_hat is:  [ 0.35083029  0.2866976   0.36247215]\n",
      "\tep: 474, reward: -21.0\n",
      "\tep: 475, reward: -21.0\n",
      "\tep: 476, reward: -21.0\n",
      "\tep: 477, reward: -21.0\n",
      "\tep: 478, reward: -20.0\n",
      "\tep: 479, reward: -21.0\n",
      "ep: 480, reward: -20.0, mean reward: -20.496858\n",
      "\tep: 481, reward: -19.0\n",
      "\tep: 482, reward: -21.0\n",
      "\tep: 483, reward: -19.0\n",
      "\ty_hat is:  [ 0.35940433  0.2625072   0.37808838]\n",
      "\tep: 484, reward: -21.0\n",
      "\tep: 485, reward: -21.0\n",
      "\tep: 486, reward: -21.0\n",
      "\ty_hat is:  [ 0.37079754  0.24666044  0.38254201]\n",
      "\tep: 487, reward: -21.0\n",
      "\tep: 488, reward: -20.0\n",
      "\tep: 489, reward: -20.0\n",
      "ep: 490, reward: -21.0, mean reward: -20.488354\n",
      "\tep: 491, reward: -21.0\n",
      "\ty_hat is:  [ 0.3407968   0.28111118  0.37809202]\n",
      "\tep: 492, reward: -21.0\n",
      "\tep: 493, reward: -21.0\n",
      "\tep: 494, reward: -21.0\n",
      "\tep: 495, reward: -20.0\n",
      "\tep: 496, reward: -19.0\n",
      "\tep: 497, reward: -18.0\n",
      "\tep: 498, reward: -21.0\n",
      "\tep: 499, reward: -21.0\n",
      "ep: 500, reward: -19.0, mean reward: -20.459446\n",
      "\tep: 501, reward: -21.0\n",
      "\tep: 502, reward: -21.0\n",
      "\tep: 503, reward: -19.0\n",
      "\tep: 504, reward: -21.0\n",
      "\ty_hat is:  [ 0.27897167  0.27440941  0.44661885]\n",
      "\tep: 505, reward: -19.0\n",
      "\ty_hat is:  [ 0.30286476  0.29350945  0.40362579]\n",
      "\tep: 506, reward: -20.0\n",
      "\tep: 507, reward: -20.0\n",
      "\tep: 508, reward: -19.0\n",
      "\tep: 509, reward: -21.0\n",
      "ep: 510, reward: -19.0, mean reward: -20.414561\n",
      "\ty_hat is:  [ 0.32097563  0.29247603  0.3865484 ]\n",
      "\tep: 511, reward: -21.0\n",
      "\tep: 512, reward: -20.0\n",
      "\tep: 513, reward: -21.0\n",
      "\tep: 514, reward: -21.0\n",
      "\tep: 515, reward: -19.0\n",
      "\tep: 516, reward: -19.0\n",
      "\tep: 517, reward: -21.0\n",
      "\tep: 518, reward: -20.0\n",
      "\tep: 519, reward: -19.0\n",
      "ep: 520, reward: -20.0, mean reward: -20.383479\n",
      "\tep: 521, reward: -17.0\n",
      "\tep: 522, reward: -20.0\n",
      "\ty_hat is:  [ 0.26607734  0.33175117  0.40217149]\n",
      "\tep: 523, reward: -21.0\n",
      "\tep: 524, reward: -19.0\n",
      "\tep: 525, reward: -21.0\n",
      "\tep: 526, reward: -21.0\n",
      "\tep: 527, reward: -21.0\n",
      "\tep: 528, reward: -21.0\n",
      "\tep: 529, reward: -21.0\n",
      "ep: 530, reward: -20.0, mean reward: -20.367832\n",
      "\tep: 531, reward: -21.0\n",
      "\tep: 532, reward: -20.0\n",
      "\tep: 533, reward: -21.0\n",
      "\tep: 534, reward: -21.0\n",
      "\tep: 535, reward: -21.0\n",
      "\tep: 536, reward: -20.0\n",
      "\tep: 537, reward: -21.0\n",
      "\ty_hat is:  [ 0.32018837  0.347413    0.33239859]\n",
      "\tep: 538, reward: -19.0\n",
      "\tep: 539, reward: -21.0\n",
      "ep: 540, reward: -20.0, mean reward: -20.379843\n",
      "\tep: 541, reward: -20.0\n",
      "\ty_hat is:  [ 0.33145273  0.33304483  0.33550245]\n",
      "\tep: 542, reward: -17.0\n",
      "\ty_hat is:  [ 0.36746833  0.29502356  0.33750817]\n",
      "\tep: 543, reward: -20.0\n",
      "\ty_hat is:  [ 0.3031424   0.31592992  0.38092771]\n",
      "\tep: 544, reward: -21.0\n",
      "\tep: 545, reward: -20.0\n",
      "\ty_hat is:  [ 0.33180904  0.30905369  0.35913721]\n",
      "\tep: 546, reward: -19.0\n",
      "\tep: 547, reward: -21.0\n",
      "\tep: 548, reward: -20.0\n",
      "\tep: 549, reward: -21.0\n",
      "ep: 550, reward: -21.0, mean reward: -20.345253\n",
      "\tep: 551, reward: -20.0\n",
      "\tep: 552, reward: -21.0\n",
      "\ty_hat is:  [ 0.30083269  0.30021924  0.39894801]\n",
      "\tep: 553, reward: -21.0\n",
      "\tep: 554, reward: -20.0\n",
      "\ty_hat is:  [ 0.30074835  0.33180466  0.36744699]\n",
      "\tep: 555, reward: -20.0\n",
      "\tep: 556, reward: -20.0\n",
      "\tep: 557, reward: -20.0\n",
      "\tep: 558, reward: -19.0\n",
      "\tep: 559, reward: -21.0\n",
      "\ty_hat is:  [ 0.32282633  0.32881069  0.34836295]\n",
      "ep: 560, reward: -21.0, mean reward: -20.340887\n",
      "\ty_hat is:  [ 0.3155289   0.26745486  0.41701621]\n",
      "\tep: 561, reward: -20.0\n",
      "\tep: 562, reward: -21.0\n",
      "\tep: 563, reward: -19.0\n",
      "\tep: 564, reward: -20.0\n",
      "\ty_hat is:  [ 0.35418171  0.27206057  0.37375766]\n",
      "\tep: 565, reward: -20.0\n",
      "\tep: 566, reward: -21.0\n",
      "\tep: 567, reward: -21.0\n",
      "\tep: 568, reward: -20.0\n",
      "\tep: 569, reward: -19.0\n",
      "ep: 570, reward: -21.0, mean reward: -20.327608\n",
      "\tep: 571, reward: -21.0\n",
      "\tep: 572, reward: -20.0\n",
      "\tep: 573, reward: -20.0\n",
      "\tep: 574, reward: -20.0\n",
      "\tep: 575, reward: -21.0\n",
      "\ty_hat is:  [ 0.42156622  0.27372137  0.30471241]\n",
      "\tep: 576, reward: -20.0\n",
      "\tep: 577, reward: -21.0\n",
      "\tep: 578, reward: -21.0\n",
      "\tep: 579, reward: -20.0\n",
      "ep: 580, reward: -20.0, mean reward: -20.334432\n",
      "\tep: 581, reward: -21.0\n",
      "\ty_hat is:  [ 0.36035633  0.31468913  0.32495454]\n",
      "\tep: 582, reward: -21.0\n",
      "\tep: 583, reward: -21.0\n",
      "\tep: 584, reward: -20.0\n",
      "\tep: 585, reward: -20.0\n",
      "\tep: 586, reward: -21.0\n",
      "\tep: 587, reward: -21.0\n",
      "\tep: 588, reward: -21.0\n",
      "\ty_hat is:  [ 0.44114804  0.25733262  0.30151933]\n",
      "\tep: 589, reward: -21.0\n",
      "ep: 590, reward: -20.0, mean reward: -20.369148\n",
      "\tep: 591, reward: -20.0\n",
      "\tep: 592, reward: -21.0\n",
      "\ty_hat is:  [ 0.39786926  0.25042728  0.35170346]\n",
      "\tep: 593, reward: -20.0\n",
      "\tep: 594, reward: -21.0\n",
      "\tep: 595, reward: -21.0\n",
      "\tep: 596, reward: -18.0\n",
      "\tep: 597, reward: -21.0\n",
      "\tep: 598, reward: -21.0\n",
      "\tep: 599, reward: -20.0\n",
      "ep: 600, reward: -20.0, mean reward: -20.362295\n",
      "\tep: 601, reward: -21.0\n",
      "\tep: 602, reward: -21.0\n",
      "\tep: 603, reward: -21.0\n",
      "\tep: 604, reward: -19.0\n",
      "\tep: 605, reward: -20.0\n",
      "\ty_hat is:  [ 0.35164145  0.32052937  0.32782918]\n",
      "\tep: 606, reward: -21.0\n",
      "\tep: 607, reward: -21.0\n",
      "\tep: 608, reward: -21.0\n",
      "\tep: 609, reward: -19.0\n",
      "\ty_hat is:  [ 0.38827252  0.29465318  0.31707424]\n",
      "ep: 610, reward: -20.0, mean reward: -20.365131\n",
      "\tep: 611, reward: -21.0\n",
      "\tep: 612, reward: -21.0\n",
      "\ty_hat is:  [ 0.4091188   0.28549713  0.30538404]\n",
      "\tep: 613, reward: -21.0\n",
      "\tep: 614, reward: -20.0\n",
      "\ty_hat is:  [ 0.32698509  0.33443967  0.33857527]\n",
      "\tep: 615, reward: -21.0\n",
      "\tep: 616, reward: -21.0\n",
      "\tep: 617, reward: -20.0\n",
      "\tep: 618, reward: -19.0\n",
      "\tep: 619, reward: -21.0\n",
      "\ty_hat is:  [ 0.32490507  0.30475038  0.37034455]\n",
      "ep: 620, reward: -21.0, mean reward: -20.387116\n",
      "\ty_hat is:  [ 0.40117821  0.25728026  0.34154156]\n",
      "\tep: 621, reward: -20.0\n",
      "\tep: 622, reward: -21.0\n",
      "\ty_hat is:  [ 0.43614328  0.31693134  0.24692541]\n",
      "\tep: 623, reward: -19.0\n",
      "\tep: 624, reward: -20.0\n",
      "\tep: 625, reward: -21.0\n",
      "\tep: 626, reward: -21.0\n",
      "\tep: 627, reward: -21.0\n",
      "\tep: 628, reward: -20.0\n",
      "\tep: 629, reward: -20.0\n",
      "ep: 630, reward: -21.0, mean reward: -20.388827\n",
      "\tep: 631, reward: -21.0\n",
      "\ty_hat is:  [ 0.39192423  0.28606391  0.32201186]\n",
      "\tep: 632, reward: -19.0\n",
      "\tep: 633, reward: -21.0\n",
      "\tep: 634, reward: -20.0\n",
      "\ty_hat is:  [ 0.4169226   0.2507008   0.33237651]\n",
      "\tep: 635, reward: -20.0\n",
      "\ty_hat is:  [ 0.34926885  0.31949303  0.33123809]\n",
      "\tep: 636, reward: -21.0\n",
      "\ty_hat is:  [ 0.32946908  0.2998746   0.37065634]\n",
      "\tep: 637, reward: -19.0\n",
      "\tep: 638, reward: -19.0\n",
      "\tep: 639, reward: -21.0\n",
      "ep: 640, reward: -21.0, mean reward: -20.370878\n",
      "\tep: 641, reward: -20.0\n",
      "\tep: 642, reward: -20.0\n",
      "\tep: 643, reward: -20.0\n",
      "\tep: 644, reward: -20.0\n",
      "\tep: 645, reward: -21.0\n",
      "\tep: 646, reward: -21.0\n",
      "\tep: 647, reward: -21.0\n",
      "\tep: 648, reward: -21.0\n",
      "\tep: 649, reward: -21.0\n",
      "ep: 650, reward: -20.0, mean reward: -20.383935\n",
      "\tep: 651, reward: -20.0\n",
      "\tep: 652, reward: -20.0\n",
      "\tep: 653, reward: -21.0\n",
      "\tep: 654, reward: -19.0\n",
      "\tep: 655, reward: -21.0\n",
      "\ty_hat is:  [ 0.33049667  0.32861418  0.34088919]\n",
      "\tep: 656, reward: -20.0\n",
      "\tep: 657, reward: -19.0\n",
      "\tep: 658, reward: -21.0\n",
      "\tep: 659, reward: -20.0\n",
      "ep: 660, reward: -21.0, mean reward: -20.366738\n",
      "\tep: 661, reward: -20.0\n",
      "\tep: 662, reward: -19.0\n",
      "\ty_hat is:  [ 0.3150512   0.30740312  0.37754562]\n",
      "\tep: 663, reward: -20.0\n",
      "\tep: 664, reward: -21.0\n",
      "\tep: 665, reward: -20.0\n",
      "\tep: 666, reward: -20.0\n",
      "\ty_hat is:  [ 0.36424598  0.26644117  0.36931288]\n",
      "\ty_hat is:  [ 0.32036597  0.24742435  0.43220973]\n",
      "\tep: 667, reward: -21.0\n",
      "\tep: 668, reward: -19.0\n",
      "\tep: 669, reward: -19.0\n",
      "ep: 670, reward: -20.0, mean reward: -20.321861\n",
      "\ty_hat is:  [ 0.39916915  0.3101455   0.29068533]\n",
      "\tep: 671, reward: -20.0\n",
      "\tep: 672, reward: -19.0\n",
      "\tep: 673, reward: -19.0\n",
      "\tep: 674, reward: -20.0\n",
      "\tep: 675, reward: -21.0\n",
      "\tep: 676, reward: -20.0\n",
      "\tep: 677, reward: -20.0\n",
      "\tep: 678, reward: -21.0\n",
      "\tep: 679, reward: -20.0\n",
      "ep: 680, reward: -20.0, mean reward: -20.291848\n",
      "\tep: 681, reward: -20.0\n",
      "\tep: 682, reward: -21.0\n",
      "\tep: 683, reward: -20.0\n",
      "\ty_hat is:  [ 0.43342185  0.26736429  0.29921389]\n",
      "\tep: 684, reward: -19.0\n",
      "\tep: 685, reward: -21.0\n",
      "\ty_hat is:  [ 0.33137226  0.25672621  0.41190159]\n",
      "\tep: 686, reward: -20.0\n",
      "\tep: 687, reward: -21.0\n",
      "\ty_hat is:  [ 0.30224562  0.31272584  0.38502851]\n",
      "\tep: 688, reward: -21.0\n",
      "\tep: 689, reward: -20.0\n",
      "ep: 690, reward: -21.0, mean reward: -20.302769\n",
      "\ty_hat is:  [ 0.31314373  0.27127105  0.41558525]\n",
      "\tep: 691, reward: -20.0\n",
      "\tep: 692, reward: -19.0\n",
      "\tep: 693, reward: -21.0\n",
      "\tep: 694, reward: -21.0\n",
      "\tep: 695, reward: -21.0\n",
      "\tep: 696, reward: -21.0\n",
      "\tep: 697, reward: -20.0\n",
      "\tep: 698, reward: -21.0\n",
      "\ty_hat is:  [ 0.3305479   0.29465032  0.37480178]\n",
      "\tep: 699, reward: -21.0\n",
      "ep: 700, reward: -21.0, mean reward: -20.332143\n",
      "\tep: 701, reward: -20.0\n",
      "\ty_hat is:  [ 0.3209939   0.28447816  0.39452791]\n",
      "\tep: 702, reward: -19.0\n",
      "\tep: 703, reward: -20.0\n",
      "\ty_hat is:  [ 0.35722104  0.29704574  0.3457332 ]\n",
      "\tep: 704, reward: -21.0\n",
      "\tep: 705, reward: -21.0\n",
      "\tep: 706, reward: -20.0\n",
      "\tep: 707, reward: -21.0\n",
      "\tep: 708, reward: -21.0\n",
      "\tep: 709, reward: -18.0\n",
      "ep: 710, reward: -21.0, mean reward: -20.319786\n",
      "\tep: 711, reward: -20.0\n",
      "\tep: 712, reward: -19.0\n",
      "\tep: 713, reward: -19.0\n",
      "\tep: 714, reward: -20.0\n",
      "\tep: 715, reward: -20.0\n",
      "\tep: 716, reward: -20.0\n",
      "\ty_hat is:  [ 0.33437446  0.30159315  0.36403239]\n",
      "\tep: 717, reward: -20.0\n",
      "\ty_hat is:  [ 0.31763688  0.33466381  0.34769934]\n",
      "\tep: 718, reward: -19.0\n",
      "\ty_hat is:  [ 0.30327731  0.30195716  0.39476562]\n",
      "\tep: 719, reward: -20.0\n",
      "ep: 720, reward: -20.0, mean reward: -20.260859\n",
      "\tep: 721, reward: -21.0\n",
      "\tep: 722, reward: -21.0\n",
      "\tep: 723, reward: -20.0\n",
      "\tep: 724, reward: -21.0\n",
      "\tep: 725, reward: -21.0\n",
      "\tep: 726, reward: -21.0\n",
      "\tep: 727, reward: -21.0\n",
      "\tep: 728, reward: -21.0\n",
      "\tep: 729, reward: -20.0\n",
      "ep: 730, reward: -21.0, mean reward: -20.312314\n",
      "\tep: 731, reward: -20.0\n",
      "\tep: 732, reward: -21.0\n",
      "\tep: 733, reward: -21.0\n",
      "\tep: 734, reward: -21.0\n",
      "\tep: 735, reward: -21.0\n",
      "\tep: 736, reward: -21.0\n",
      "\tep: 737, reward: -20.0\n",
      "\ty_hat is:  [ 0.28193361  0.35438743  0.36367893]\n",
      "\tep: 738, reward: -20.0\n",
      "\tep: 739, reward: -21.0\n",
      "\ty_hat is:  [ 0.29193798  0.39657035  0.31149176]\n",
      "ep: 740, reward: -21.0, mean reward: -20.349430\n",
      "\tep: 741, reward: -21.0\n",
      "\tep: 742, reward: -21.0\n",
      "\tep: 743, reward: -21.0\n",
      "\tep: 744, reward: -21.0\n",
      "\tep: 745, reward: -20.0\n",
      "\tep: 746, reward: -20.0\n",
      "\tep: 747, reward: -20.0\n",
      "\ty_hat is:  [ 0.27769449  0.35562217  0.3666833 ]\n",
      "\tep: 748, reward: -21.0\n",
      "\tep: 749, reward: -21.0\n",
      "\ty_hat is:  [ 0.33568564  0.36476666  0.29954773]\n",
      "ep: 750, reward: -21.0, mean reward: -20.382817\n",
      "\tep: 751, reward: -21.0\n",
      "\tep: 752, reward: -21.0\n",
      "\tep: 753, reward: -21.0\n",
      "\ty_hat is:  [ 0.28242058  0.44751674  0.27006266]\n",
      "\tep: 754, reward: -20.0\n",
      "\tep: 755, reward: -21.0\n",
      "\tep: 756, reward: -21.0\n",
      "\tep: 757, reward: -20.0\n",
      "\tep: 758, reward: -21.0\n",
      "\tep: 759, reward: -21.0\n",
      "ep: 760, reward: -21.0, mean reward: -20.422713\n",
      "\tep: 761, reward: -19.0\n",
      "\tep: 762, reward: -20.0\n",
      "\tep: 763, reward: -17.0\n",
      "\tep: 764, reward: -19.0\n",
      "\tep: 765, reward: -18.0\n",
      "\tep: 766, reward: -21.0\n",
      "\tep: 767, reward: -21.0\n",
      "\tep: 768, reward: -19.0\n",
      "\tep: 769, reward: -20.0\n",
      "ep: 770, reward: -21.0, mean reward: -20.336270\n",
      "\tep: 771, reward: -21.0\n",
      "\tep: 772, reward: -21.0\n",
      "\tep: 773, reward: -20.0\n",
      "\tep: 774, reward: -21.0\n",
      "\ty_hat is:  [ 0.40578386  0.28585437  0.30836177]\n",
      "\tep: 775, reward: -21.0\n",
      "\tep: 776, reward: -21.0\n",
      "\tep: 777, reward: -20.0\n",
      "\tep: 778, reward: -20.0\n",
      "\tep: 779, reward: -21.0\n",
      "ep: 780, reward: -19.0, mean reward: -20.350910\n",
      "\tep: 781, reward: -20.0\n",
      "\ty_hat is:  [ 0.33980182  0.31380334  0.34639481]\n",
      "\tep: 782, reward: -20.0\n",
      "\tep: 783, reward: -20.0\n",
      "\ty_hat is:  [ 0.29645714  0.31609973  0.3874431 ]\n",
      "\tep: 784, reward: -20.0\n",
      "\tep: 785, reward: -21.0\n",
      "\tep: 786, reward: -21.0\n",
      "\tep: 787, reward: -21.0\n",
      "\tep: 788, reward: -19.0\n",
      "\tep: 789, reward: -21.0\n",
      "\ty_hat is:  [ 0.29871795  0.35950562  0.34177649]\n",
      "\ty_hat is:  [ 0.34236237  0.33174664  0.32589096]\n",
      "ep: 790, reward: -20.0, mean reward: -20.346275\n",
      "\tep: 791, reward: -19.0\n",
      "\tep: 792, reward: -19.0\n",
      "\tep: 793, reward: -20.0\n",
      "\ty_hat is:  [ 0.37416503  0.2787593   0.34707564]\n",
      "\tep: 794, reward: -21.0\n",
      "\tep: 795, reward: -20.0\n",
      "\tep: 796, reward: -18.0\n",
      "\ty_hat is:  [ 0.31181851  0.27173606  0.41644543]\n",
      "\tep: 797, reward: -20.0\n",
      "\ty_hat is:  [ 0.32946897  0.28423223  0.38629887]\n",
      "\tep: 798, reward: -20.0\n",
      "\tep: 799, reward: -21.0\n",
      "ep: 800, reward: -20.0, mean reward: -20.294905\n",
      "\tep: 801, reward: -21.0\n",
      "\tep: 802, reward: -19.0\n",
      "\tep: 803, reward: -21.0\n",
      "\tep: 804, reward: -21.0\n",
      "\tep: 805, reward: -21.0\n",
      "\ty_hat is:  [ 0.28268006  0.31213233  0.40518761]\n",
      "\ty_hat is:  [ 0.27942622  0.31092232  0.40965149]\n",
      "\tep: 806, reward: -20.0\n",
      "\tep: 807, reward: -20.0\n",
      "\tep: 808, reward: -20.0\n",
      "\ty_hat is:  [ 0.26851618  0.31846881  0.41301504]\n",
      "\tep: 809, reward: -20.0\n",
      "ep: 810, reward: -21.0, mean reward: -20.304860\n",
      "\tep: 811, reward: -21.0\n",
      "\tep: 812, reward: -21.0\n",
      "\tep: 813, reward: -21.0\n",
      "\tep: 814, reward: -21.0\n",
      "\tep: 815, reward: -20.0\n",
      "\tep: 816, reward: -21.0\n",
      "\tep: 817, reward: -21.0\n",
      "\tep: 818, reward: -21.0\n",
      "\tep: 819, reward: -21.0\n",
      "ep: 820, reward: -21.0, mean reward: -20.361818\n",
      "\ty_hat is:  [ 0.30991814  0.35970506  0.33037689]\n",
      "\ty_hat is:  [ 0.3550531   0.34623209  0.29871485]\n",
      "\tep: 821, reward: -21.0\n",
      "\tep: 822, reward: -20.0\n",
      "\ty_hat is:  [ 0.32048804  0.34910807  0.33040389]\n",
      "\tep: 823, reward: -17.0\n",
      "\tep: 824, reward: -21.0\n",
      "\tep: 825, reward: -21.0\n",
      "\tep: 826, reward: -20.0\n",
      "\tep: 827, reward: -20.0\n",
      "\tep: 828, reward: -20.0\n",
      "\tep: 829, reward: -19.0\n",
      "\ty_hat is:  [ 0.2986421   0.39318499  0.30817294]\n",
      "ep: 830, reward: -21.0, mean reward: -20.327419\n",
      "\tep: 831, reward: -21.0\n",
      "\tep: 832, reward: -21.0\n",
      "\tep: 833, reward: -21.0\n",
      "\tep: 834, reward: -20.0\n",
      "\tep: 835, reward: -21.0\n",
      "\tep: 836, reward: -21.0\n",
      "\tep: 837, reward: -21.0\n",
      "\ty_hat is:  [ 0.35221371  0.36254999  0.28523618]\n",
      "\tep: 838, reward: -21.0\n",
      "\tep: 839, reward: -21.0\n",
      "ep: 840, reward: -21.0, mean reward: -20.382315\n",
      "\tep: 841, reward: -21.0\n",
      "\tep: 842, reward: -21.0\n",
      "\tep: 843, reward: -20.0\n",
      "\tep: 844, reward: -20.0\n",
      "\tep: 845, reward: -21.0\n",
      "\tep: 846, reward: -20.0\n",
      "\tep: 847, reward: -21.0\n",
      "\tep: 848, reward: -20.0\n",
      "\tep: 849, reward: -21.0\n",
      "\ty_hat is:  [ 0.29109657  0.37851676  0.3303867 ]\n",
      "ep: 850, reward: -19.0, mean reward: -20.383235\n",
      "\tep: 851, reward: -21.0\n",
      "\tep: 852, reward: -21.0\n",
      "\ty_hat is:  [ 0.35470054  0.33941755  0.30588198]\n",
      "\tep: 853, reward: -20.0\n",
      "\tep: 854, reward: -20.0\n",
      "\tep: 855, reward: -21.0\n",
      "\tep: 856, reward: -21.0\n",
      "\ty_hat is:  [ 0.25852031  0.33149222  0.40998754]\n",
      "\tep: 857, reward: -19.0\n",
      "\tep: 858, reward: -21.0\n",
      "\tep: 859, reward: -19.0\n",
      "\ty_hat is:  [ 0.32195565  0.3383607   0.33968365]\n",
      "ep: 860, reward: -20.0, mean reward: -20.374267\n",
      "\ty_hat is:  [ 0.32130814  0.29686764  0.3818242 ]\n",
      "\tep: 861, reward: -21.0\n",
      "\tep: 862, reward: -21.0\n",
      "\tep: 863, reward: -18.0\n",
      "\tep: 864, reward: -21.0\n",
      "\ty_hat is:  [ 0.2887063   0.30656859  0.40472507]\n",
      "\tep: 865, reward: -20.0\n",
      "\tep: 866, reward: -20.0\n",
      "\tep: 867, reward: -20.0\n",
      "\tep: 868, reward: -21.0\n",
      "\tep: 869, reward: -21.0\n",
      "ep: 870, reward: -21.0, mean reward: -20.377318\n",
      "\ty_hat is:  [ 0.32079834  0.31357765  0.36562401]\n",
      "\tep: 871, reward: -21.0\n",
      "\tep: 872, reward: -21.0\n",
      "\tep: 873, reward: -20.0\n",
      "\ty_hat is:  [ 0.29370958  0.30986649  0.39642397]\n",
      "\tep: 874, reward: -20.0\n",
      "\tep: 875, reward: -20.0\n",
      "\tep: 876, reward: -21.0\n",
      "\tep: 877, reward: -20.0\n",
      "\tep: 878, reward: -21.0\n",
      "\tep: 879, reward: -21.0\n",
      "\ty_hat is:  [ 0.28507516  0.33540311  0.37952173]\n",
      "ep: 880, reward: -20.0, mean reward: -20.388909\n",
      "\tep: 881, reward: -20.0\n",
      "\ty_hat is:  [ 0.28481871  0.33789968  0.37728164]\n",
      "\tep: 882, reward: -21.0\n",
      "\tep: 883, reward: -21.0\n",
      "\tep: 884, reward: -21.0\n",
      "\tep: 885, reward: -20.0\n",
      "\tep: 886, reward: -21.0\n",
      "\tep: 887, reward: -21.0\n",
      "\ty_hat is:  [ 0.29432595  0.26140389  0.44427016]\n",
      "\tep: 888, reward: -20.0\n",
      "\ty_hat is:  [ 0.23397835  0.27038911  0.4956325 ]\n",
      "\tep: 889, reward: -20.0\n",
      "ep: 890, reward: -20.0, mean reward: -20.398994\n",
      "\tep: 891, reward: -21.0\n",
      "\tep: 892, reward: -21.0\n",
      "\tep: 893, reward: -20.0\n",
      "\tep: 894, reward: -21.0\n",
      "\tep: 895, reward: -20.0\n",
      "\tep: 896, reward: -21.0\n",
      "\tep: 897, reward: -21.0\n",
      "\ty_hat is:  [ 0.20660804  0.34281999  0.45057195]\n",
      "\tep: 898, reward: -21.0\n",
      "\tep: 899, reward: -21.0\n",
      "\ty_hat is:  [ 0.21300176  0.27918097  0.50781727]\n",
      "ep: 900, reward: -21.0, mean reward: -20.437630\n",
      "\tep: 901, reward: -20.0\n",
      "\tep: 902, reward: -21.0\n",
      "\tep: 903, reward: -21.0\n",
      "\ty_hat is:  [ 0.29302678  0.25290313  0.45407003]\n",
      "\tep: 904, reward: -21.0\n",
      "\tep: 905, reward: -20.0\n",
      "\ty_hat is:  [ 0.22557762  0.33341026  0.44101211]\n",
      "\tep: 906, reward: -21.0\n",
      "\tep: 907, reward: -21.0\n",
      "\tep: 908, reward: -20.0\n",
      "\tep: 909, reward: -20.0\n",
      "ep: 910, reward: -21.0, mean reward: -20.453057\n",
      "\tep: 911, reward: -20.0\n",
      "\tep: 912, reward: -21.0\n",
      "\tep: 913, reward: -20.0\n",
      "\tep: 914, reward: -21.0\n",
      "\tep: 915, reward: -21.0\n",
      "\tep: 916, reward: -21.0\n",
      "\tep: 917, reward: -21.0\n",
      "\ty_hat is:  [ 0.2687414   0.29707658  0.43418205]\n",
      "\tep: 918, reward: -19.0\n",
      "\tep: 919, reward: -20.0\n",
      "ep: 920, reward: -20.0, mean reward: -20.447397\n",
      "\tep: 921, reward: -21.0\n",
      "\ty_hat is:  [ 0.33116439  0.26347569  0.40535986]\n",
      "\tep: 922, reward: -19.0\n",
      "\tep: 923, reward: -20.0\n",
      "\tep: 924, reward: -21.0\n",
      "\tep: 925, reward: -21.0\n",
      "\tep: 926, reward: -21.0\n",
      "\tep: 927, reward: -20.0\n",
      "\tep: 928, reward: -19.0\n",
      "\tep: 929, reward: -21.0\n",
      "\ty_hat is:  [ 0.29131171  0.2616756   0.44701269]\n",
      "ep: 930, reward: -19.0, mean reward: -20.423155\n",
      "\tep: 931, reward: -20.0\n",
      "\tep: 932, reward: -21.0\n",
      "\tep: 933, reward: -21.0\n",
      "\tep: 934, reward: -21.0\n",
      "\ty_hat is:  [ 0.29175919  0.2553485   0.45289236]\n",
      "\tep: 935, reward: -20.0\n",
      "\tep: 936, reward: -21.0\n",
      "\ty_hat is:  [ 0.33131444  0.32644168  0.34224388]\n",
      "\tep: 937, reward: -21.0\n",
      "\tep: 938, reward: -21.0\n",
      "\tep: 939, reward: -21.0\n",
      "ep: 940, reward: -20.0, mean reward: -20.449667\n",
      "\tep: 941, reward: -21.0\n",
      "\tep: 942, reward: -20.0\n",
      "\tep: 943, reward: -21.0\n",
      "\tep: 944, reward: -19.0\n",
      "\tep: 945, reward: -21.0\n",
      "\tep: 946, reward: -20.0\n",
      "\ty_hat is:  [ 0.32176229  0.34058234  0.3376554 ]\n",
      "\tep: 947, reward: -20.0\n",
      "\tep: 948, reward: -21.0\n",
      "\ty_hat is:  [ 0.3008343   0.37003633  0.32912937]\n",
      "\tep: 949, reward: -19.0\n",
      "ep: 950, reward: -19.0, mean reward: -20.415122\n",
      "\ty_hat is:  [ 0.31754455  0.30075896  0.38169649]\n",
      "\tep: 951, reward: -20.0\n",
      "\tep: 952, reward: -20.0\n",
      "\tep: 953, reward: -20.0\n",
      "\tep: 954, reward: -20.0\n",
      "\ty_hat is:  [ 0.32208744  0.37562734  0.30228525]\n",
      "\tep: 955, reward: -20.0\n",
      "\tep: 956, reward: -21.0\n",
      "\ty_hat is:  [ 0.33852476  0.33159426  0.32988098]\n",
      "\tep: 957, reward: -19.0\n",
      "\tep: 958, reward: -21.0\n",
      "\tep: 959, reward: -20.0\n",
      "ep: 960, reward: -21.0, mean reward: -20.395133\n",
      "\tep: 961, reward: -19.0\n",
      "\tep: 962, reward: -21.0\n",
      "\ty_hat is:  [ 0.29195008  0.44330499  0.26474491]\n",
      "\tep: 963, reward: -21.0\n",
      "\tep: 964, reward: -21.0\n",
      "\tep: 965, reward: -20.0\n",
      "\tep: 966, reward: -21.0\n",
      "\tep: 967, reward: -21.0\n",
      "\tep: 968, reward: -21.0\n",
      "\tep: 969, reward: -21.0\n",
      "ep: 970, reward: -21.0, mean reward: -20.425189\n",
      "\tep: 971, reward: -20.0\n",
      "\tep: 972, reward: -21.0\n",
      "\tep: 973, reward: -21.0\n",
      "\tep: 974, reward: -20.0\n",
      "\tep: 975, reward: -21.0\n",
      "\tep: 976, reward: -21.0\n",
      "\tep: 977, reward: -21.0\n",
      "\tep: 978, reward: -21.0\n",
      "\tep: 979, reward: -21.0\n",
      "ep: 980, reward: -21.0, mean reward: -20.461601\n",
      "\tep: 981, reward: -19.0\n",
      "\tep: 982, reward: -20.0\n",
      "\tep: 983, reward: -21.0\n",
      "\tep: 984, reward: -19.0\n",
      "\tep: 985, reward: -21.0\n",
      "\tep: 986, reward: -21.0\n",
      "\tep: 987, reward: -21.0\n",
      "\tep: 988, reward: -19.0\n",
      "\tep: 989, reward: -21.0\n",
      "ep: 990, reward: -21.0, mean reward: -20.447152\n",
      "\tep: 991, reward: -21.0\n",
      "\tep: 992, reward: -20.0\n",
      "\tep: 993, reward: -21.0\n",
      "\tep: 994, reward: -21.0\n",
      "\tep: 995, reward: -19.0\n",
      "\ty_hat is:  [ 0.32959893  0.38615531  0.2842457 ]\n",
      "\ty_hat is:  [ 0.36617985  0.35081971  0.28300038]\n",
      "\tep: 996, reward: -21.0\n",
      "\tep: 997, reward: -21.0\n",
      "\tep: 998, reward: -21.0\n",
      "\tep: 999, reward: -21.0\n",
      "ep: 1000, reward: -21.0, mean reward: -20.471767\n",
      "\tep: 1001, reward: -21.0\n",
      "\tep: 1002, reward: -21.0\n",
      "\tep: 1003, reward: -20.0\n",
      "\tep: 1004, reward: -21.0\n",
      "\ty_hat is:  [ 0.3271006   0.34630546  0.32659388]\n",
      "\tep: 1005, reward: -20.0\n",
      "\tep: 1006, reward: -20.0\n",
      "\tep: 1007, reward: -20.0\n",
      "\tep: 1008, reward: -19.0\n",
      "\tep: 1009, reward: -21.0\n",
      "ep: 1010, reward: -19.0, mean reward: -20.444534\n",
      "\tep: 1011, reward: -21.0\n",
      "\tep: 1012, reward: -20.0\n",
      "\tep: 1013, reward: -21.0\n",
      "\tep: 1014, reward: -19.0\n",
      "\tep: 1015, reward: -20.0\n",
      "\tep: 1016, reward: -21.0\n",
      "\tep: 1017, reward: -21.0\n",
      "\tep: 1018, reward: -21.0\n",
      "\tep: 1019, reward: -21.0\n",
      "\ty_hat is:  [ 0.30941594  0.35636565  0.33421832]\n",
      "ep: 1020, reward: -20.0, mean reward: -20.450080\n",
      "\tep: 1021, reward: -18.0\n",
      "\tep: 1022, reward: -21.0\n",
      "\tep: 1023, reward: -21.0\n",
      "\tep: 1024, reward: -19.0\n",
      "\tep: 1025, reward: -21.0\n",
      "\tep: 1026, reward: -20.0\n",
      "\tep: 1027, reward: -21.0\n",
      "\tep: 1028, reward: -20.0\n",
      "\tep: 1029, reward: -21.0\n",
      "ep: 1030, reward: -20.0, mean reward: -20.427020\n",
      "\tep: 1031, reward: -20.0\n",
      "\tep: 1032, reward: -21.0\n",
      "\tep: 1033, reward: -21.0\n",
      "\tep: 1034, reward: -21.0\n",
      "\tep: 1035, reward: -21.0\n",
      "\tep: 1036, reward: -21.0\n",
      "\tep: 1037, reward: -20.0\n",
      "\ty_hat is:  [ 0.32598761  0.37915331  0.29485902]\n",
      "\tep: 1038, reward: -21.0\n",
      "\tep: 1039, reward: -19.0\n",
      "ep: 1040, reward: -21.0, mean reward: -20.443169\n",
      "\tep: 1041, reward: -20.0\n",
      "\tep: 1042, reward: -21.0\n",
      "\tep: 1043, reward: -20.0\n",
      "\tep: 1044, reward: -21.0\n",
      "\tep: 1045, reward: -21.0\n",
      "\tep: 1046, reward: -19.0\n",
      "\tep: 1047, reward: -20.0\n",
      "\ty_hat is:  [ 0.31590274  0.40759555  0.27650172]\n",
      "\tep: 1048, reward: -20.0\n",
      "\tep: 1049, reward: -21.0\n",
      "ep: 1050, reward: -21.0, mean reward: -20.439240\n",
      "\ty_hat is:  [ 0.31551078  0.40816975  0.2763195 ]\n",
      "\tep: 1051, reward: -21.0\n",
      "\ty_hat is:  [ 0.36050123  0.36516279  0.27433595]\n",
      "\tep: 1052, reward: -21.0\n",
      "\tep: 1053, reward: -21.0\n",
      "\ty_hat is:  [ 0.31964967  0.42375261  0.25659776]\n",
      "\tep: 1054, reward: -21.0\n",
      "\tep: 1055, reward: -21.0\n",
      "\tep: 1056, reward: -21.0\n",
      "\tep: 1057, reward: -21.0\n",
      "\tep: 1058, reward: -21.0\n",
      "\tep: 1059, reward: -21.0\n",
      "ep: 1060, reward: -21.0, mean reward: -20.492859\n",
      "\tep: 1061, reward: -21.0\n",
      "\tep: 1062, reward: -20.0\n",
      "\tep: 1063, reward: -20.0\n",
      "\tep: 1064, reward: -21.0\n",
      "\tep: 1065, reward: -21.0\n",
      "\ty_hat is:  [ 0.32222542  0.35822475  0.3195498 ]\n",
      "\tep: 1066, reward: -21.0\n",
      "\tep: 1067, reward: -19.0\n",
      "\tep: 1068, reward: -21.0\n",
      "\tep: 1069, reward: -21.0\n",
      "\ty_hat is:  [ 0.31529328  0.35002446  0.3346822 ]\n",
      "ep: 1070, reward: -21.0, mean reward: -20.503397\n",
      "\tep: 1071, reward: -21.0\n",
      "\tep: 1072, reward: -20.0\n",
      "\tep: 1073, reward: -20.0\n",
      "\ty_hat is:  [ 0.28941464  0.3985258   0.31205955]\n",
      "\tep: 1074, reward: -21.0\n",
      "\tep: 1075, reward: -20.0\n",
      "\tep: 1076, reward: -19.0\n",
      "\tep: 1077, reward: -21.0\n",
      "\tep: 1078, reward: -21.0\n",
      "\tep: 1079, reward: -21.0\n",
      "ep: 1080, reward: -20.0, mean reward: -20.493611\n",
      "\tep: 1081, reward: -21.0\n",
      "\tep: 1082, reward: -21.0\n",
      "\tep: 1083, reward: -21.0\n",
      "\ty_hat is:  [ 0.30079243  0.38914546  0.31006211]\n",
      "\tep: 1084, reward: -20.0\n",
      "\ty_hat is:  [ 0.24334852  0.48723856  0.26941293]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4aa1a61b28cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# step the environment and get new measurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mreward_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/core.pyc\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_before_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_after_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/gym/envs/atari/atari_env.pyc\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnp_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/atari_py/ale_python_interface.pyc\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('X') ; ax.set_ylabel('Y')\n",
    "ax.set_xlim(0,1000) ; ax.set_ylim(-21,-19)\n",
    "pxs, pys = [], []\n",
    "\n",
    "print 'episode {}: starting up...'.format(episode_number)\n",
    "while True:\n",
    "#     if True: env.render()\n",
    "\n",
    "    # preprocess the observation\n",
    "    cur_x = prepro(observation)\n",
    "    x = cur_x - prev_x if prev_x is not None else np.zeros(n_obs)\n",
    "    prev_x = cur_x\n",
    "\n",
    "    # stochastically sample a policy from the network\n",
    "    action = agent.act(np.reshape(x, (1,-1)))\n",
    "\n",
    "    # step the environment and get new measurements\n",
    "    observation, reward, done, info = env.step(action + 1)\n",
    "    agent.rs.append(reward)\n",
    "    reward_sum += reward\n",
    "    \n",
    "    if done:\n",
    "        running_reward = running_reward * 0.99 + reward_sum * 0.01\n",
    "        agent.learn()\n",
    "\n",
    "        # visualization\n",
    "        pxs.append(episode_number)\n",
    "        pys.append(running_reward)\n",
    "        if episode_number % 10 == 0:\n",
    "            print 'ep: {}, reward: {}, mean reward: {:3f}'.format(episode_number, reward_sum, running_reward)\n",
    "            plt_dynamic(pxs, pys, ax)\n",
    "        else:\n",
    "            print '\\tep: {}, reward: {}'.format(episode_number, reward_sum)\n",
    "            \n",
    "#         if episode_number % 50 == 0:\n",
    "#             saver.save(agent.sess, save_path, global_step=agent.global_step)\n",
    "#             print \"SAVED MODEL #{}\".format(agent.global_step)\n",
    "        \n",
    "        # lame stuff\n",
    "        cur_x = None\n",
    "        episode_number += 1 # the Next Episode\n",
    "        observation = env.reset() # reset env\n",
    "        reward_sum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rnn_models/model.ckpt-1085'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.save(agent.sess, save_path, global_step=agent.global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Agent instance has no attribute 'aprob'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-78b64fecc9c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_aprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Agent instance has no attribute 'aprob'"
     ]
    }
   ],
   "source": [
    "print agent.aprob\n",
    "print agent.batch_aprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
